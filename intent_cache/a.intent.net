FANN_FLO_2.1
num_layers=3
learning_rate=0.700000
connection_rate=1.000000
network_type=0
learning_momentum=0.000000
training_algorithm=2
train_error_function=1
train_stop_function=1
cascade_output_change_fraction=0.010000
quickprop_decay=-0.000100
quickprop_mu=1.750000
rprop_increase_factor=1.200000
rprop_decrease_factor=0.500000
rprop_delta_min=0.000000
rprop_delta_max=50.000000
rprop_delta_zero=0.100000
cascade_output_stagnation_epochs=12
cascade_candidate_change_fraction=0.010000
cascade_candidate_stagnation_epochs=12
cascade_max_out_epochs=150
cascade_min_out_epochs=50
cascade_max_cand_epochs=150
cascade_min_cand_epochs=50
cascade_num_candidate_groups=2
bit_fail_limit=1.00000000000000005551e-01
cascade_candidate_limit=1.00000000000000000000e+03
cascade_weight_multiplier=4.00000000000000022204e-01
cascade_activation_functions_count=10
cascade_activation_functions=3 5 7 8 10 11 14 15 16 17 
cascade_activation_steepnesses_count=4
cascade_activation_steepnesses=2.50000000000000000000e-01 5.00000000000000000000e-01 7.50000000000000000000e-01 1.00000000000000000000e+00 
layer_sizes=12 11 2 
scale_included=0
neurons (num_inputs, activation_function, activation_steepness)=(0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (12, 6, 5.00000000000000000000e-01) (12, 6, 5.00000000000000000000e-01) (12, 6, 5.00000000000000000000e-01) (12, 6, 5.00000000000000000000e-01) (12, 6, 5.00000000000000000000e-01) (12, 6, 5.00000000000000000000e-01) (12, 6, 5.00000000000000000000e-01) (12, 6, 5.00000000000000000000e-01) (12, 6, 5.00000000000000000000e-01) (12, 6, 5.00000000000000000000e-01) (0, 6, 0.00000000000000000000e+00) (11, 6, 5.00000000000000000000e-01) (0, 6, 0.00000000000000000000e+00) 
connections (connected_to_neuron, weight)=(0, 8.97364527478642948211e+00) (1, 1.48686341927208726110e-01) (2, 1.93311698720612296087e-01) (3, 2.57816433892407104178e-01) (4, 1.56397260711350266638e-01) (5, -4.48528058628636372429e-01) (6, -8.37370114733181014621e-01) (7, -8.72922002323191392748e-01) (8, -3.37569404341807655090e-01) (9, -4.51677845329880478520e-01) (10, -6.44642510643681637683e-02) (11, -1.48439374157728291165e-02) (0, 6.99866126832356050258e-01) (1, 3.71655822032883748074e-02) (2, 1.37528225802798581556e-01) (3, 6.83286413783028984126e-02) (4, 1.04668900393863034681e-01) (5, 5.14256875748656860914e-01) (6, 2.13040372593170462823e-01) (7, 2.94996276677044755310e-01) (8, 6.51043776973692533971e-01) (9, 5.47846701576999994820e-01) (10, 4.33688041023850612277e-01) (11, -4.19151324602345942694e-01) (0, 8.33246443030228212123e-01) (1, 1.02336496137996030287e-01) (2, 1.68864727252916076161e-02) (3, 6.57097697490647697505e-02) (4, 1.05259716743425074670e-02) (5, 7.17481766324126080114e-01) (6, 2.36583633584743796563e-01) (7, 3.81092636197333134440e-01) (8, 6.28026937297876175492e-01) (9, 3.60302115141873158244e-01) (10, 4.54884197150318247971e-01) (11, -4.07176602455358027655e-01) (0, 2.12939284369328767355e+01) (1, 9.65808369803752009286e-02) (2, 6.08264953482474113322e-02) (3, 2.41197511612209203324e-01) (4, 2.46132835804256322465e-01) (5, -4.22178465979216988035e-01) (6, -7.40075037200838226070e-01) (7, -8.94078215854221314274e-01) (8, -1.77596993956259524561e-01) (9, -1.22629446075985382159e+00) (10, -8.13137954178075050837e-02) (11, 1.35742703397726371950e-01) (0, 1.01044108842499857914e+00) (1, 7.87133802400029169988e-01) (2, 7.49238018618023859929e-01) (3, 9.18805387542641405219e-01) (4, 7.82066398040450083684e-01) (5, 1.39463278935840695461e+00) (6, 9.22410882297840739596e-01) (7, 7.73357370841052715882e-01) (8, 4.88248571945685327922e-01) (9, 8.37374485379220989678e-01) (10, 8.63526796842374877450e-01) (11, 1.31369488401800338373e+00) (0, 2.31462508920284054659e-01) (1, 1.03239956925210193961e-01) (2, 1.43095832000073669432e-01) (3, 6.66978207030860942295e-02) (4, 1.22905451486405567496e-01) (5, -4.89762997065456284762e-01) (6, -6.69531501911886151035e-01) (7, -5.41264987867623226236e-01) (8, -2.06077212943313908822e-01) (9, -1.93581853273621845579e-01) (10, -4.05882457843577848511e-01) (11, 2.84664323794104279219e-01) (0, 6.63904700037827089076e-01) (1, 3.31924855941727672826e-02) (2, 1.32622882747073483900e-01) (3, 1.20180919999078456017e-02) (4, 4.89599108928635770588e-02) (5, 1.03460568804150776501e+00) (6, 2.19276095438258877834e-01) (7, 4.01446248543293138233e-01) (8, 3.94625695448413749133e-01) (9, 3.11273674151679613509e-01) (10, 3.37728235795299258637e-01) (11, -4.17909596599211730084e-01) (0, 1.02232592676766520512e+00) (1, 7.64214806930220591497e-01) (2, 8.35055154488480333441e-01) (3, 7.30225925074017512273e-01) (4, 8.04657523260510432195e-01) (5, 1.40412163273981183131e+00) (6, 9.44784843865254742035e-01) (7, 9.31019192207610091216e-01) (8, 6.31316922797220847485e-01) (9, 1.01833893252150908815e+00) (10, 8.20675667390969310055e-01) (11, 1.30181876285463515863e+00) (0, 1.07890906721403045943e+00) (1, -1.23252174132016639740e-01) (2, -6.31047620107207385409e-02) (3, -1.01384600870755681168e-01) (4, -8.20591880609068957675e-02) (5, 8.08243948250575550141e-01) (6, 7.24157821168269544287e-01) (7, 2.61344048164437625648e-01) (8, 6.50176544929693678299e-01) (9, 2.79882218907149538101e-01) (10, 5.45323467458500799054e-01) (11, -3.42397755464800723768e-01) (0, 1.33459565350948050622e+00) (1, 8.43599625261834740186e-01) (2, 8.37320894332936882520e-01) (3, 7.63964094551614625317e-01) (4, 7.62455456288865907055e-01) (5, 1.83475892064361190137e+00) (6, 1.17724146471289969895e+00) (7, 7.79437748497613824838e-01) (8, 4.88341674400824488078e-01) (9, 1.50549516681891870640e+00) (10, 7.78675656781342540036e-01) (11, 1.01117648330694143155e-02) (12, -1.70867501498713436625e-01) (13, 6.73499605345454610550e-01) (14, 6.13825993334180086691e-01) (15, -4.02342448614956160746e-01) (16, -5.45035564024298271879e-02) (17, -3.03134598839630564626e-01) (18, 6.92508882569995320999e-01) (19, -9.52895172555296710026e-02) (20, 9.58489780484579112496e-01) (21, -1.06032509418234111020e-01) (22, 2.73375563421965395161e-01) 
