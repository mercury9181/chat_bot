FANN_FLO_2.1
num_layers=3
learning_rate=0.700000
connection_rate=1.000000
network_type=0
learning_momentum=0.000000
training_algorithm=2
train_error_function=1
train_stop_function=1
cascade_output_change_fraction=0.010000
quickprop_decay=-0.000100
quickprop_mu=1.750000
rprop_increase_factor=1.200000
rprop_decrease_factor=0.500000
rprop_delta_min=0.000000
rprop_delta_max=50.000000
rprop_delta_zero=0.100000
cascade_output_stagnation_epochs=12
cascade_candidate_change_fraction=0.010000
cascade_candidate_stagnation_epochs=12
cascade_max_out_epochs=150
cascade_min_out_epochs=50
cascade_max_cand_epochs=150
cascade_min_cand_epochs=50
cascade_num_candidate_groups=2
bit_fail_limit=1.00000000000000005551e-01
cascade_candidate_limit=1.00000000000000000000e+03
cascade_weight_multiplier=4.00000000000000022204e-01
cascade_activation_functions_count=10
cascade_activation_functions=3 5 7 8 10 11 14 15 16 17 
cascade_activation_steepnesses_count=4
cascade_activation_steepnesses=2.50000000000000000000e-01 5.00000000000000000000e-01 7.50000000000000000000e-01 1.00000000000000000000e+00 
layer_sizes=11 11 2 
scale_included=0
neurons (num_inputs, activation_function, activation_steepness)=(0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (11, 6, 5.00000000000000000000e-01) (11, 6, 5.00000000000000000000e-01) (11, 6, 5.00000000000000000000e-01) (11, 6, 5.00000000000000000000e-01) (11, 6, 5.00000000000000000000e-01) (11, 6, 5.00000000000000000000e-01) (11, 6, 5.00000000000000000000e-01) (11, 6, 5.00000000000000000000e-01) (11, 6, 5.00000000000000000000e-01) (11, 6, 5.00000000000000000000e-01) (0, 6, 0.00000000000000000000e+00) (11, 6, 5.00000000000000000000e-01) (0, 6, 0.00000000000000000000e+00) 
connections (connected_to_neuron, weight)=(0, -3.83557690076399004919e-01) (1, 5.87541058958465090001e-01) (2, 5.84647521675521364415e-01) (3, 4.43291403652125715062e-01) (4, 4.52104106844359754369e-01) (5, 2.57046163476202149667e+00) (6, 2.69621994740459580697e+00) (7, 4.07424010521202450974e+00) (8, -2.84297640732209144776e-01) (9, 3.27814944371823369096e+00) (10, 3.00498154809787809683e-01) (0, -3.13190361253786242468e-01) (1, 5.91985225976401796544e-01) (2, 5.86849406660491457188e-01) (3, 5.59127286375457388523e-01) (4, 4.87319726795846397405e-01) (5, 2.64352185673210282602e+00) (6, 2.86230146272242214067e+00) (7, 3.98732164686947188059e+00) (8, -2.07649308553616573914e-01) (9, 3.19903279379252492021e+00) (10, 3.69814229061916410757e-01) (0, -7.73936214975882497136e-01) (1, -3.11224313618522971381e-02) (2, -1.80245042050061837768e-01) (3, -1.54105816239295617676e-01) (4, -7.45984019877296844481e-02) (5, 9.87716687509691104729e-01) (6, 9.15636798033391818841e-01) (7, 1.40182805977381463869e+00) (8, -1.02570169388629853224e-01) (9, 5.91518693931955663601e-01) (10, 8.28879668821021348135e-02) (0, -3.71158456198740160925e-01) (1, 4.44129363001281141088e-01) (2, 6.18735730946952333653e-01) (3, 6.09099224508697023595e-01) (4, 4.41532403529578565404e-01) (5, 2.66704187936279435434e+00) (6, 2.51880105233881135263e+00) (7, 4.07513882404594784958e+00) (8, -2.47264798096100746339e-01) (9, 3.30365935251359044145e+00) (10, 3.36164784481838285757e-01) (0, 1.37196067243549931630e-02) (1, -9.61092746548224630132e-01) (2, -1.07892008750872725464e+00) (3, -9.02127100817729177251e-01) (4, -1.02229406564669722535e+00) (5, -2.24554268824131375570e-01) (6, -2.22798800276787167807e-01) (7, 2.07086336796431375040e-02) (8, 1.13656575849366475728e-01) (9, -2.47135786520511990805e-01) (10, -1.10176303899522287644e+00) (0, 1.07786443753353844421e+00) (1, -1.58210303191274298529e-01) (2, -2.33596257422298086981e-01) (3, -2.10869039897054327826e-01) (4, -2.55413841013044040640e-01) (5, -1.36691925350207066359e+00) (6, -1.39748939919847225966e+00) (7, -2.47673187035894937225e+00) (8, 7.18823915256389889272e-01) (9, -2.13779362133027373005e+00) (10, 1.77951690804485834763e-01) (0, 2.01244578250159111832e+00) (1, 1.19644727514221824172e-01) (2, 6.22389837662722378298e-02) (3, 1.84267263815834664298e-01) (4, 1.39628868506386422110e-01) (5, -3.27269247713037947367e-01) (6, -3.07711149545856932352e-01) (7, -6.90025024610458448393e-01) (8, 6.96446643738729997963e-01) (9, -6.27421014878845939577e-01) (10, -1.40900568952471522133e-01) (0, 1.16312225831858406799e+00) (1, -3.66332919804854273416e-01) (2, -3.31937530545992731668e-01) (3, -3.62814330963892817117e-01) (4, -2.72313767580790400125e-01) (5, -1.37370286557453846754e+00) (6, -1.27936494398492550673e+00) (7, -2.47019719708538598724e+00) (8, 8.60197482539543423208e-01) (9, -2.23922899952412901570e+00) (10, 2.85786748927359113281e-01) (0, -4.81429567329454577429e-01) (1, 5.20340614319735994542e-01) (2, 5.95227331221992006505e-01) (3, 4.76317759902173398778e-01) (4, 5.38904846013480764988e-01) (5, 2.68908090538475175180e+00) (6, 2.56388692951891083993e+00) (7, 3.93863317555218062083e+00) (8, -2.92766283563057838624e-01) (9, 3.18782440111283360551e+00) (10, 3.45778089812114775015e-01) (0, 1.51409829522482697328e+00) (1, 5.68252764205481319948e-02) (2, 9.16153527359511027361e-02) (3, 1.22755419419243491652e-01) (4, 1.07469771013691581252e-01) (5, -3.55827047469564783366e-01) (6, -2.70694940330931110850e-01) (7, -6.25165403383670881254e-01) (8, 5.65489703385813280434e-01) (9, -1.68987749782268409371e-01) (10, -1.31663633426338938515e-01) (11, 5.68588503147482215994e-01) (12, 5.59008487011312782400e-01) (13, 1.43909747268072907289e+00) (14, 6.10939272190450965994e-01) (15, 7.69775078248458727304e-02) (16, -2.17870029664095743449e-01) (17, -8.08327051929999318425e-01) (18, -1.58108952498492105754e-01) (19, 6.10506795789121925466e-01) (20, -8.08157417110968556706e-01) (21, -5.41815189430011334704e-02) 
